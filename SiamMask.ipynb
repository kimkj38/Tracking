{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SiamMask\n",
    "\n",
    "**Blog Review**    \n",
    "<https://velog.io/@kimkj38/%EB%85%BC%EB%AC%B8-%EB%A6%AC%EB%B7%B0-SaimMask-Fast-Online-Object-Tracking-and-Segmentation-A-Unifying-Approach>   \n",
    "\n",
    "**Code reference**   \n",
    "<https://github.com/foolwood/SiamMask/tree/master/models>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from utils.anchors import Anchors\n",
    "\n",
    "\n",
    "class SiamMask(nn.Module):\n",
    "    def __init__(self, anchors=None, o_sz=63, g_sz=127):\n",
    "        super(SiamMask, self).__init__()\n",
    "        self.anchors = anchors  # anchor_cfg\n",
    "        self.anchor_num = len(self.anchors[\"ratios\"]) * len(self.anchors[\"scales\"])\n",
    "        self.anchor = Anchors(anchors)\n",
    "        self.features = None\n",
    "        self.rpn_model = None\n",
    "        self.mask_model = None\n",
    "        self.o_sz = o_sz\n",
    "        self.g_sz = g_sz\n",
    "        self.upSample = nn.UpsamplingBilinear2d(size=[g_sz, g_sz])\n",
    "\n",
    "        self.all_anchors = None\n",
    "\n",
    "    def set_all_anchors(self, image_center, size):\n",
    "        # cx,cy,w,h\n",
    "        if not self.anchor.generate_all_anchors(image_center, size):\n",
    "            return\n",
    "        all_anchors = self.anchor.all_anchors[1]  # cx, cy, w, h\n",
    "        self.all_anchors = torch.from_numpy(all_anchors).float().cuda()\n",
    "        self.all_anchors = [self.all_anchors[i] for i in range(4)]\n",
    "\n",
    "    def feature_extractor(self, x):\n",
    "        return self.features(x)\n",
    "\n",
    "    def rpn(self, template, search):\n",
    "        pred_cls, pred_loc = self.rpn_model(template, search)\n",
    "        return pred_cls, pred_loc\n",
    "\n",
    "    def mask(self, template, search):\n",
    "        pred_mask = self.mask_model(template, search)\n",
    "        return pred_mask\n",
    "\n",
    "    def _add_rpn_loss(self, label_cls, label_loc, lable_loc_weight, label_mask, label_mask_weight,\n",
    "                      rpn_pred_cls, rpn_pred_loc, rpn_pred_mask):\n",
    "        rpn_loss_cls = select_cross_entropy_loss(rpn_pred_cls, label_cls)\n",
    "\n",
    "        rpn_loss_loc = weight_l1_loss(rpn_pred_loc, label_loc, lable_loc_weight)\n",
    "\n",
    "        rpn_loss_mask, iou_m, iou_5, iou_7 = select_mask_logistic_loss(rpn_pred_mask, label_mask, label_mask_weight)\n",
    "\n",
    "        return rpn_loss_cls, rpn_loss_loc, rpn_loss_mask, iou_m, iou_5, iou_7\n",
    "\n",
    "    def run(self, template, search, softmax=False):\n",
    "        \"\"\"\n",
    "        run network\n",
    "        \"\"\"\n",
    "        #x와 z의 feature map 각각 뽑아내기\n",
    "        template_feature = self.feature_extractor(template)\n",
    "        search_feature = self.feature_extractor(search)\n",
    "        #rpn을 통해 cls, loc 예측\n",
    "        rpn_pred_cls, rpn_pred_loc = self.rpn(template_feature, search_feature)\n",
    "        #mask 통해 w x h의 binary 값 예측\n",
    "        rpn_pred_mask = self.mask(template_feature, search_feature)  # (b, 63*63, w, h)\n",
    "        \n",
    "        if softmax:\n",
    "            rpn_pred_cls = self.softmax(rpn_pred_cls)\n",
    "        return rpn_pred_cls, rpn_pred_loc, rpn_pred_mask, template_feature, search_feature\n",
    "\n",
    "    def softmax(self, cls):\n",
    "        b, a2, h, w = cls.size()\n",
    "        cls = cls.view(b, 2, a2//2, h, w)\n",
    "        cls = cls.permute(0, 2, 3, 4, 1).contiguous()\n",
    "        cls = F.log_softmax(cls, dim=4)\n",
    "        return cls\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        :param input: dict of input with keys of:\n",
    "                'template': [b, 3, h1, w1], input template image.\n",
    "                'search': [b, 3, h2, w2], input search image.\n",
    "                'label_cls':[b, max_num_gts, 5] or None(self.training==False),\n",
    "                                     each gt contains x1,y1,x2,y2,class.\n",
    "        :return: dict of loss, predict, accuracy\n",
    "        \"\"\"\n",
    "        template = input['template']\n",
    "        search = input['search']\n",
    "        if self.training:\n",
    "            label_cls = input['label_cls']\n",
    "            label_loc = input['label_loc']\n",
    "            lable_loc_weight = input['label_loc_weight']\n",
    "            label_mask = input['label_mask']\n",
    "            label_mask_weight = input['label_mask_weight']\n",
    "\n",
    "        rpn_pred_cls, rpn_pred_loc, rpn_pred_mask, template_feature, search_feature = \\\n",
    "            self.run(template, search, softmax=self.training)\n",
    "\n",
    "        outputs = dict()\n",
    "\n",
    "        outputs['predict'] = [rpn_pred_loc, rpn_pred_cls, rpn_pred_mask, template_feature, search_feature]\n",
    "\n",
    "        if self.training:\n",
    "            rpn_loss_cls, rpn_loss_loc, rpn_loss_mask, iou_acc_mean, iou_acc_5, iou_acc_7 = \\\n",
    "                self._add_rpn_loss(label_cls, label_loc, lable_loc_weight, label_mask, label_mask_weight,\n",
    "                                   rpn_pred_cls, rpn_pred_loc, rpn_pred_mask)\n",
    "            outputs['losses'] = [rpn_loss_cls, rpn_loss_loc, rpn_loss_mask]\n",
    "            outputs['accuracy'] = [iou_acc_mean, iou_acc_5, iou_acc_7]\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    #cls와 loc에 대한 각각의 template\n",
    "    def template(self, z):\n",
    "        self.zf = self.feature_extractor(z)\n",
    "        cls_kernel, loc_kernel = self.rpn_model.template(self.zf)\n",
    "        return cls_kernel, loc_kernel\n",
    "\n",
    "    #rpn을 거쳐 cls와 loc 예측값 도출\n",
    "    def track(self, x, cls_kernel=None, loc_kernel=None, softmax=False):\n",
    "        xf = self.feature_extractor(x)\n",
    "        rpn_pred_cls, rpn_pred_loc = self.rpn_model.track(xf, cls_kernel, loc_kernel)\n",
    "        if softmax:\n",
    "            rpn_pred_cls = self.softmax(rpn_pred_cls)\n",
    "        return rpn_pred_cls, rpn_pred_loc\n",
    "\n",
    "#cls는 cross entropy loss\n",
    "def get_cls_loss(pred, label, select):\n",
    "    if select.nelement() == 0: return pred.sum()*0. #nelement(): 텐서의 요소 수 리턴\n",
    "    pred = torch.index_select(pred, 0, select) \n",
    "    label = torch.index_select(label, 0, select)\n",
    "    \"\"\"\n",
    "    index_select(x,0,indices): x에서 indices에 해당하는 행만 리턴\n",
    "    index_select(x,1,indices): x에서 indices에 해당하는 열만 리턴\n",
    "    \"\"\"\n",
    "\n",
    "    return F.nll_loss(pred, label) #negative log likelihood loss\n",
    "\n",
    "\n",
    "def select_cross_entropy_loss(pred, label):\n",
    "    pred = pred.view(-1, 2) #positive, negative 2개\n",
    "    label = label.view(-1)\n",
    "    pos = Variable(label.data.eq(1).nonzero().squeeze()).cuda()\n",
    "    neg = Variable(label.data.eq(0).nonzero().squeeze()).cuda()\n",
    "    #torch.eq(1): 1에 해당하는 element만 True로 리턴\n",
    "    #torch.nonzero: 0이 아닌 element의 인덱스 리턴\n",
    "\n",
    "    loss_pos = get_cls_loss(pred, label, pos)\n",
    "    loss_neg = get_cls_loss(pred, label, neg)\n",
    "    return loss_pos * 0.5 + loss_neg * 0.5\n",
    "\n",
    "#loc는 Smooth L1 \n",
    "def weight_l1_loss(pred_loc, label_loc, loss_weight):\n",
    "    \"\"\"\n",
    "    :param pred_loc: [b, 4k, h, w]\n",
    "    :param label_loc: [b, 4k, h, w]\n",
    "    :param loss_weight:  [b, k, h, w]\n",
    "    :return: loc loss value\n",
    "    \"\"\"\n",
    "    b, _, sh, sw = pred_loc.size()\n",
    "    pred_loc = pred_loc.view(b, 4, -1, sh, sw)\n",
    "    diff = (pred_loc - label_loc).abs()\n",
    "    diff = diff.sum(dim=1).view(b, -1, sh, sw)\n",
    "    loss = diff * loss_weight\n",
    "    return loss.sum().div(b)\n",
    "\n",
    "#mask에는 logistic loss\n",
    "def select_mask_logistic_loss(p_m, mask, weight, o_sz=63, g_sz=127):\n",
    "    weight = weight.view(-1)\n",
    "    pos = Variable(weight.data.eq(1).nonzero().squeeze())\n",
    "    if pos.nelement() == 0: return p_m.sum() * 0, p_m.sum() * 0, p_m.sum() * 0, p_m.sum() * 0\n",
    "\n",
    "    p_m = p_m.permute(0, 2, 3, 1).contiguous().view(-1, 1, o_sz, o_sz)\n",
    "    p_m = torch.index_select(p_m, 0, pos)\n",
    "    p_m = nn.UpsamplingBilinear2d(size=[g_sz, g_sz])(p_m) #interpolation 통해 스케일을 늘림\n",
    "    p_m = p_m.view(-1, g_sz * g_sz)\n",
    "\n",
    "    mask_uf = F.unfold(mask, (g_sz, g_sz), padding=32, stride=8)\n",
    "    mask_uf = torch.transpose(mask_uf, 1, 2).contiguous().view(-1, g_sz * g_sz)\n",
    "\n",
    "    mask_uf = torch.index_select(mask_uf, 0, pos)\n",
    "    loss = F.soft_margin_loss(p_m, mask_uf)\n",
    "    iou_m, iou_5, iou_7 = iou_measure(p_m, mask_uf)\n",
    "    return loss, iou_m, iou_5, iou_7\n",
    "\n",
    "\n",
    "def iou_measure(pred, label):\n",
    "    pred = pred.ge(0) #0이상인 요소들 True\n",
    "    mask_sum = pred.eq(1).add(label.eq(1))\n",
    "    intxn = torch.sum(mask_sum == 2, dim=1).float()\n",
    "    union = torch.sum(mask_sum > 0, dim=1).float()\n",
    "    iou = intxn/union\n",
    "    return torch.mean(iou), (torch.sum(iou > 0.5).float()/iou.shape[0]), (torch.sum(iou > 0.7).float()/iou.shape[0])\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    p_m = torch.randn(4, 63*63, 25, 25)\n",
    "    cls = torch.randn(4, 1, 25, 25) > 0.9\n",
    "    mask = torch.randn(4, 1, 255, 255) * 2 - 1\n",
    "\n",
    "    loss = select_mask_logistic_loss(p_m, mask, cls)\n",
    "    print(loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
